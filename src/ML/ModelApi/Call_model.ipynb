{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent/'ML'\n",
    "SAMPLE = ROOT/'sample_submission.csv'\n",
    "TRAIN = ROOT/'train_x.csv'\n",
    "TARGET = ROOT/'train_y.csv'\n",
    "TEST = ROOT/'test_x.csv'\n",
    "RESULT = ROOT/'test_y.csv'\n",
    "\n",
    "ID_COLS = ['series_id', 'measurement_num']\n",
    "\n",
    "x_cols = {\n",
    "    'series_id' : np.uint32,\n",
    "    'measurement_num': np.uint32,\n",
    "    'x' : np.float32,\n",
    "    'y' : np.float32,\n",
    "    'z' : np.float32\n",
    "}\n",
    "\n",
    "y_cols = {\n",
    "    'series_id' : np.uint32,\n",
    "    'activity' : str\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SepConv1d(nn.Module):\n",
    "    \"\"\"A simple separable convolution implementation.\n",
    "    \n",
    "    The separable convlution is a method to reduce number of the parameters \n",
    "    in the deep learning network for slight decrease in predictions quality.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no, kernel, stride, pad):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(ni, ni, kernel, stride, padding=pad, groups=ni)\n",
    "        self.pointwise = nn.Conv1d(ni, no, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "    \n",
    "class SepConv1d(nn.Module):\n",
    "    \"\"\"Implementes a 1-d convolution with 'batteries included'.\n",
    "    \n",
    "    The module adds (optionally) activation function and dropout layers right after\n",
    "    a separable convolution layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no, kernel, stride, pad, drop=None,\n",
    "                 activ=lambda: nn.ReLU(inplace=True)):\n",
    "    \n",
    "        super().__init__()\n",
    "        assert drop is None or (0.0 < drop < 1.0)\n",
    "        layers = [_SepConv1d(ni, no, kernel, stride, pad)]\n",
    "        if activ:\n",
    "            layers.append(activ())\n",
    "        if drop is not None:\n",
    "            layers.append(nn.Dropout(drop))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.layers(x)\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n",
    "\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.view(x.size(0), -1)\n",
    "        return x.view(-1)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, raw_ni, no, drop=.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.raw = nn.Sequential(\n",
    "            SepConv1d(raw_ni,  32, 5, 2, 3, drop=drop),\n",
    "            SepConv1d(    32,  64, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(    64, 128, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(   128, 256, 5, 4, 2),\n",
    "            Flatten(),\n",
    "            nn.Dropout(drop), nn.Linear(256, 64), nn.ReLU(inplace=True),\n",
    "            nn.Dropout(drop), nn.Linear( 64, 64), nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(64, 64), nn.ReLU(inplace=True), nn.Linear(64, no))\n",
    "        \n",
    "    def forward(self, t_raw):\n",
    "        raw_out = self.raw(t_raw)\n",
    "        #fft_out = self.fft(t_fft)\n",
    "        t_in = torch.cat([raw_out], dim=1)\n",
    "        out = self.out(t_in)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (raw): Sequential(\n",
       "    (0): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(30, 30, kernel_size=(5,), stride=(2,), padding=(3,), groups=30)\n",
       "          (pointwise): Conv1d(30, 32, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(32, 32, kernel_size=(5,), stride=(4,), padding=(2,), groups=32)\n",
       "          (pointwise): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(64, 64, kernel_size=(5,), stride=(4,), padding=(2,), groups=64)\n",
       "          (pointwise): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(4,), padding=(2,), groups=128)\n",
       "          (pointwise): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Flatten()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = Classifier(30, 9)\n",
    "model.load_state_dict(torch.load('best.pth', map_location=\"cuda:0\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(X, y, test_size=0.2, dropcols = ID_COLS, time_dim_first=False):\n",
    "    enc = LabelEncoder()\n",
    "    y_enc = enc.fit_transform(y)\n",
    "    X_grouped = create_grouped_array(X)\n",
    "    if time_dim_first:\n",
    "        X_grouped = X_grouped.transpose(0, 2, 1)\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_grouped, y_enc, test_size = 0.1)\n",
    "    X_train, X_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (X_train, X_valid)]\n",
    "    y_train, y_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (y_train, y_valid)]\n",
    "\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    valid_ds = TensorDataset(X_valid, y_valid)\n",
    "    \n",
    "    return train_ds, valid_ds, enc\n",
    "\n",
    "def create_grouped_array(data, group_col='series_id', drop_cols=ID_COLS):\n",
    "        X_grouped = np.row_stack([\n",
    "            group.drop(columns=drop_cols).values[None]\n",
    "            for _, group in data.groupby(group_col)\n",
    "        ])\n",
    "        \n",
    "        return X_grouped\n",
    "\n",
    "def create_test_dataset(X, drop_cols=ID_COLS):\n",
    "    X_grouped = np.row_stack([\n",
    "        group.drop(columns=drop_cols).values[None]\n",
    "        for _, group in X.groupby('series_id')\n",
    "    ])\n",
    "    X_grouped = torch.tensor(X_grouped.transpose(0, 2, 1)).float()\n",
    "    y_fake = torch.tensor([0] * len(X_grouped)).long()\n",
    "    return TensorDataset(X_grouped, y_fake)\n",
    "    \n",
    "def create_loaders(train_ds, valid_ds, bs=512, jobs=0):\n",
    "    train_dl = DataLoader(train_ds, bs, shuffle=True, num_workers=jobs)\n",
    "    valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=jobs)\n",
    "    \n",
    "    return train_dl, valid_dl\n",
    "\n",
    "def accuracy(output, target):\n",
    "    return(output.argmax(dim=1) == target).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(x_tst):\n",
    "    test_dl = DataLoader(create_test_dataset(x_tst), batch_size=64, shuffle=False)\n",
    "    test = []\n",
    "\n",
    "    for batch, _ in test_dl:\n",
    "        batch = batch.permute(0, 2, 1)\n",
    "        out = model(batch.cuda())\n",
    "        y_hat = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        test += y_hat.tolist()\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst = pd.read_csv('walk_dataframe_ex.csv', usecols = x_cols.keys(), dtype=x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_tst = pd.read_csv('dataframe_ex.csv', usecols = x_cols.keys(), dtype=x_cols)\n",
    "type(get_prediction(f_tst)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(x_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:8000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import json \n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/', methods=['POST',])\n",
    "def data_post():\n",
    "    if request.method == 'POST':\n",
    "        text = request.data.decode(\"utf-8\")\n",
    "        p_dict = eval(text)\n",
    "        data = p_dict['data']\n",
    "        df = pd.DataFrame([x.split(',') for x in data.split('\\n')[1:-1]][:30], columns=[x for x in data.split('\\n')[0].split(',')])\n",
    "        df_len = len(df)\n",
    "        df.insert(0, \"measurement_num\", [i for i in range(df_len)])\n",
    "        df.insert(0, \"series_id\", [0] * df_len)\n",
    "        df = df.astype({'series_id': np.uint32, 'measurement_num': np.uint32, 'x':np.float32, 'y':np.float32, 'z':np.float32})\n",
    "        # df.dtypes\n",
    "        # result = 0:낙상 / 1:걷기\n",
    "        pred_start_time = time.time()\n",
    "        result = get_prediction(df)\n",
    "        pred_end_time = time.time()\n",
    "        print(p_dict['id'], result[0])\n",
    "        print('prediction time', pred_end_time - pred_start_time)\n",
    "        # 낙상인 경우에만 서버에 결과와 함께 전송한다. \n",
    "        if result == 0:\n",
    "            r = requests.post('http://203.246.112.155:5000/push', data={'watch_id' : p_dict['id'], 'fall_result' : 'fall'})\n",
    "        return json.dumps({'status' : 200, 'result': result[0]})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"model_api\" (lazy loading)\r\n",
      " * Environment: production\r\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\r\n",
      "   Use a production WSGI server instead.\r\n",
      " * Debug mode: off\r\n",
      " * Running on http://0.0.0.0:8000/ (Press CTRL+C to quit)\r\n"
     ]
    }
   ],
   "source": [
    "!cat nohup.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
