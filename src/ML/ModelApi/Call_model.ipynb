{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent/'ML'\n",
    "SAMPLE = ROOT/'sample_submission.csv'\n",
    "TRAIN = ROOT/'train_x.csv'\n",
    "TARGET = ROOT/'train_y.csv'\n",
    "TEST = ROOT/'test_x.csv'\n",
    "RESULT = ROOT/'test_y.csv'\n",
    "\n",
    "ID_COLS = ['series_id', 'measurement_num']\n",
    "\n",
    "x_cols = {\n",
    "    'series_id' : np.uint32,\n",
    "    'measurement_num': np.uint32,\n",
    "    'x' : np.float32,\n",
    "    'y' : np.float32,\n",
    "    'z' : np.float32\n",
    "}\n",
    "\n",
    "y_cols = {\n",
    "    'series_id' : np.uint32,\n",
    "    'activity' : str\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"simple version\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.cuda() for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (rnn): LSTM(3, 10, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = LSTMClassifier(3, 10, 3, 2)\n",
    "model.load_state_dict(torch.load('best.pth', map_location=\"cuda:0\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(X, y, test_size=0.2, dropcols = ID_COLS, time_dim_first=False):\n",
    "    enc = LabelEncoder()\n",
    "    y_enc = enc.fit_transform(y)\n",
    "    X_grouped = create_grouped_array(X)\n",
    "    if time_dim_first:\n",
    "        X_grouped = X_grouped.transpose(0, 2, 1)\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_grouped, y_enc, test_size = 0.1)\n",
    "    X_train, X_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (X_train, X_valid)]\n",
    "    y_train, y_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (y_train, y_valid)]\n",
    "\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    valid_ds = TensorDataset(X_valid, y_valid)\n",
    "    \n",
    "    return train_ds, valid_ds, enc\n",
    "\n",
    "def create_grouped_array(data, group_col='series_id', drop_cols=ID_COLS):\n",
    "        X_grouped = np.row_stack([\n",
    "            group.drop(columns=drop_cols).values[None]\n",
    "            for _, group in data.groupby(group_col)\n",
    "        ])\n",
    "        \n",
    "        return X_grouped\n",
    "\n",
    "def create_test_dataset(X, drop_cols=ID_COLS):\n",
    "    X_grouped = np.row_stack([\n",
    "        group.drop(columns=drop_cols).values[None]\n",
    "        for _, group in X.groupby('series_id')\n",
    "    ])\n",
    "    X_grouped = torch.tensor(X_grouped.transpose(0, 2, 1)).float()\n",
    "    y_fake = torch.tensor([0] * len(X_grouped)).long()\n",
    "    return TensorDataset(X_grouped, y_fake)\n",
    "    \n",
    "def create_loaders(train_ds, valid_ds, bs=512, jobs=0):\n",
    "    train_dl = DataLoader(train_ds, bs, shuffle=True, num_workers=jobs)\n",
    "    valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=jobs)\n",
    "    \n",
    "    return train_dl, valid_dl\n",
    "\n",
    "def accuracy(output, target):\n",
    "    return(output.argmax(dim=1) == target).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(x_tst):\n",
    "    test_dl = DataLoader(create_test_dataset(x_tst), batch_size=64, shuffle=False)\n",
    "    test = []\n",
    "\n",
    "    for batch, _ in test_dl:\n",
    "        batch = batch.permute(0, 2, 1)\n",
    "        out = model(batch.cuda())\n",
    "        y_hat = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        test += y_hat.tolist()\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst = pd.read_csv('walk_dataframe_ex.csv', usecols = x_cols.keys(), dtype=x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(x_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:8000/ (Press CTRL+C to quit)\n",
      "61.254.101.173 - - [28/May/2020 19:31:57] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171666 0\n",
      "prediction time 0.020517826080322266\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import json \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/', methods=['POST',])\n",
    "def data_post():\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            text = request.data.decode(\"utf-8\")\n",
    "            p_dict = eval(text)\n",
    "            data = p_dict['data']\n",
    "            df = pd.DataFrame([x.split(',') for x in data.split('\\n')[1:-1]], columns=[x for x in data.split('\\n')[0].split(',')])\n",
    "            df_len = len(df)\n",
    "            df.insert(0, \"measurement_num\", [i for i in range(df_len)])\n",
    "            df.insert(0, \"series_id\", [0] * df_len)\n",
    "            df = df.astype({'series_id': np.uint32, 'measurement_num': np.uint32, 'x':np.float32, 'y':np.float32, 'z':np.float32})\n",
    "            df.dtypes\n",
    "            # result = 0:낙상 / 1:걷기\n",
    "            pred_start_time = time.time()\n",
    "            result = get_prediction(df)\n",
    "            pred_end_time = time.time()\n",
    "            print(p_dict['id'], result[0])\n",
    "            print('prediction time', pred_end_time - pred_start_time)\n",
    "            return json.dumps({'status' : 200, 'result': result[0]})\n",
    "        except:\n",
    "            return json.dumps({'status' : 400})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
